{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tensorflow.python.keras.callbacks import keras_model_summary\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Input, Dense, Flatten, Dropout, Concatenate, Layer, LeakyReLU, Reshape, AveragePooling2D, Add\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from time import perf_counter, sleep\n",
    "import threading\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Add):\n",
    "\t# init with default value\n",
    "\tdef __init__(self, alpha=0.0, **kwargs):\n",
    "\t\tsuper(WeightedSum, self).__init__(**kwargs)\n",
    "\t\tself.alpha = K.variable(alpha, name='ws_alpha')\n",
    " \n",
    "\t# output a weighted sum of inputs\n",
    "\tdef _merge_function(self, inputs):\n",
    "\t\toutput = (self.alpha*inputs[0]) + ((1.0 - self.alpha)*inputs[1])\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(Layer):\n",
    "    '''\n",
    "    pixel-wise feature vector normalization layer\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    " \n",
    "    def call(self, inputs):\n",
    "        values = inputs**2.0\n",
    "        mean_values = K.mean(values, axis=-1, keepdims=True)\n",
    "        mean_values += 1.0e-8\n",
    "        l2 = K.sqrt(mean_values)\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStdev(Layer):\n",
    "    '''\n",
    "    mean standard deviation across each pixel coord\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean = K.mean(inputs, axis=0, keepdims=True)\n",
    "        mean_sq_diff = K.mean(K.square(inputs - mean), axis=0, keepdims=True) + 1e-8\n",
    "        mean_pix = K.mean(K.sqrt(mean_sq_diff), keepdims=True)\n",
    "        shape = K.shape(inputs)\n",
    "        output = K.tile(mean_pix, [shape[0], shape[1], shape[2], 1])\n",
    "        return K.concatenate([inputs, output], axis=-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[-1] += 1\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add __len__\n",
    "# TODO shuffle inputs and get them batch by batch instead of random sample\n",
    "class ImageGenerator(object):\n",
    "    def __init__(self, images_folder_path, initial_images_size=4, batch_size=32, image_channels=3):\n",
    "        self.__images_folder_path = images_folder_path\n",
    "        self.__images_size = initial_images_size\n",
    "        self.__batch_size = batch_size\n",
    "        self.__image_channels = image_channels\n",
    "        \n",
    "        self.__filenames = []\n",
    "        \n",
    "        self.__cached_bank = 0\n",
    "        self.__cached_batch = [None, None]\n",
    "        self.__cached_size = [0, 0]\n",
    "        self.__cached_ready = [True, True]\n",
    "\n",
    "        for _, _, fnames in os.walk(self.__images_folder_path):\n",
    "            for fname in fnames:\n",
    "                if fname.split('.')[-1] in ('jpg', 'jpeg'):\n",
    "                    self.__filenames.append(fname)\n",
    "            break\n",
    "    \n",
    "        print(f'Loaded {len(self.__filenames)} images.')\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self.__batch_size\n",
    "    \n",
    "    def set_images_size(self, size):\n",
    "        self.__images_size = size\n",
    "\n",
    "    def get_batch(self):\n",
    "        while not self.__cached_ready[self.__cached_bank]:\n",
    "            sleep(.01)\n",
    "        \n",
    "        result = self.__cached_batch[self.__cached_bank]\n",
    "        result_size = self.__cached_size[self.__cached_bank]\n",
    "        \n",
    "        self.__cached_bank ^= 1\n",
    "        self.__cached_ready[self.__cached_bank] = False\n",
    "        prepare_thread = threading.Thread(target=self.__prepare_cached_batch)\n",
    "        prepare_thread.start()\n",
    "        \n",
    "        if result_size != self.__images_size:\n",
    "            # wrong size\n",
    "            return self.get_batch()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "\n",
    "    def __prepare_cached_batch(self):\n",
    "        img_size = self.__images_size\n",
    "        result = np.zeros((self.__batch_size, img_size, img_size, self.__image_channels))\n",
    "\n",
    "        fnames = sample(self.__filenames, self.__batch_size)\n",
    "\n",
    "        for i in range(self.__batch_size):\n",
    "            img = cv2.imread(os.path.join(self.__images_folder_path, fnames[i]))[:,:,::-1]\n",
    "            min_size = min(img.shape[:2])\n",
    "            img = img[(img.shape[0] - min_size)//2:(img.shape[0] + min_size)//2,\n",
    "                      (img.shape[1] - min_size)//2:(img.shape[1] + min_size)//2]\n",
    "            img = cv2.resize(img, (img_size,)*2).astype(np.float32)\n",
    "            img -= img.min()\n",
    "            img /= (img.max() + 1e-9)\n",
    "            # [0, 1] -> [-1, 1]\n",
    "            img *= 2.\n",
    "            img -= 1.\n",
    "            if len(img.shape) == 2:\n",
    "                img = img[:,:,np.newaxis]\n",
    "            result[i,] = img[:,:,:self.__image_channels]\n",
    "        \n",
    "        self.__cached_batch[self.__cached_bank] = result\n",
    "        self.__cached_size[self.__cached_bank] = img_size\n",
    "        self.__cached_ready[self.__cached_bank] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add gradient penalty\n",
    "# TODO add progress bar\n",
    "# TODO change epoch to use all data\n",
    "from email.mime import image\n",
    "\n",
    "\n",
    "class ProgressiveGAN(object):\n",
    "    __latent_dim                : int\n",
    "    __initial_image_size        : int\n",
    "    __final_image_size          : int\n",
    "    __image_channels            : int\n",
    "    __gan_optimizer             : (str | keras.optimizers.Optimizer)\n",
    "    __discriminator_optimizer   : (str | keras.optimizers.Optimizer)\n",
    "    \n",
    "    __steps                     : list[int]\n",
    "\n",
    "    __generator                 : keras.Model\n",
    "    __discriminator             : keras.Model\n",
    "\n",
    "    __gan                       : keras.Model\n",
    "\n",
    "    def __init__(self, latent_dim : int =128, initial_image_size : int =4, final_image_size : int =512, image_channels : int =3, gan_optimizer : (str | keras.optimizers.Optimizer) ='adam', discriminator_optimizer : (str | keras.optimizers.Optimizer) ='adam'):\n",
    "        self.__latent_dim = latent_dim\n",
    "        self.__initial_image_size = initial_image_size\n",
    "        self.__final_image_size = final_image_size\n",
    "        self.__image_channels = image_channels\n",
    "        self.__gan_optimizer = gan_optimizer\n",
    "        self.__discriminator_optimizer = discriminator_optimizer\n",
    "\n",
    "        self.__steps = []\n",
    "        \n",
    "        image_size = initial_image_size\n",
    "        while image_size <= final_image_size:\n",
    "            self.__steps.append(image_size)\n",
    "            image_size <<= 1\n",
    "        \n",
    "        self.__total_epochs = 0\n",
    "\n",
    "        self.__generator = None\n",
    "        self.__discriminator = None\n",
    "        self.__gan = None\n",
    "\n",
    "        self.__init_generator()\n",
    "        self.__init_discriminator()\n",
    "        self.__init_gan()\n",
    "        \n",
    "        self.__timer = perf_counter()\n",
    "    \n",
    "    @property\n",
    "    def generator(self):\n",
    "        return self.__generator\n",
    "\n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        return self.__discriminator\n",
    "\n",
    "    @property\n",
    "    def gan(self):\n",
    "        return self.__gan\n",
    "\n",
    "    def sample_latent_space(self, n : int) -> np.ndarray:\n",
    "        # sample from unit hypersphere\n",
    "        normal_sample = np.random.normal(size=(n, 1, 1, self.__latent_dim))\n",
    "        \n",
    "        return normal_sample/np.sqrt((normal_sample**2).sum(axis=3))[:,:,:,np.newaxis]\n",
    "    \n",
    "    def __train_models(self, step : int, fade : bool, image_generator : ImageGenerator, epochs_per_step : int =32, discriminator_train_per_gan_train : int =5, tensorboard_callback=None):\n",
    "        generator       = self.__generator[step][int(fade)]\n",
    "        discriminator   = self.__discriminator[step][int(fade)]\n",
    "        gan             = self.__gan[step][int(fade)]\n",
    "        \n",
    "        d_loss_total = .0\n",
    "        g_loss_total = .0\n",
    "        \n",
    "        for epoch in range(epochs_per_step):\n",
    "            # adjust fade in parameter\n",
    "            if fade:\n",
    "                for model in (generator, discriminator, gan):\n",
    "                    for layer in model.layers:\n",
    "                        if isinstance(layer, WeightedSum):\n",
    "                            K.set_value(layer.alpha, epoch/epochs_per_step)\n",
    "                \n",
    "            # train discriminator\n",
    "            d_loss_generated = 0.\n",
    "            d_loss_real = 0.\n",
    "            \n",
    "            d_accuracy_generated = 0.\n",
    "            d_accuracy_real = 0.\n",
    "            for _ in range(discriminator_train_per_gan_train):\n",
    "                latent_noise = self.sample_latent_space(image_generator.batch_size)\n",
    "\n",
    "                generated_images = generator.predict(latent_noise)\n",
    "                real_images = image_generator.get_batch()\n",
    "                \n",
    "                generated_labels = -1. * np.ones((image_generator.batch_size, 1))\n",
    "                real_labels = np.ones((image_generator.batch_size, 1))\n",
    "\n",
    "                # combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "                # labels = np.ones((batch_size << 1, 1))\n",
    "                # labels[:batch_size,] = 0\n",
    "\n",
    "                generated_labels += .1 * np.random.normal(0, 1, generated_labels.shape)\n",
    "                real_labels += .1 * np.random.normal(0, 1, real_labels.shape)\n",
    "                \n",
    "                loss, accuracy = discriminator.train_on_batch(generated_images, generated_labels)\n",
    "                d_loss_generated += loss\n",
    "                d_accuracy_generated += accuracy\n",
    "                \n",
    "                loss, accuracy = discriminator.train_on_batch(real_images, real_labels)\n",
    "                d_loss_real += loss\n",
    "                d_accuracy_real += accuracy\n",
    "            \n",
    "            d_loss_generated /= discriminator_train_per_gan_train\n",
    "            d_loss_real /= discriminator_train_per_gan_train\n",
    "            \n",
    "            d_accuracy_generated /= discriminator_train_per_gan_train\n",
    "            d_accuracy_real /= discriminator_train_per_gan_train\n",
    "            \n",
    "            d_loss = (d_loss_generated + d_loss_real)/2\n",
    "            d_accuracy = (d_accuracy_generated + d_accuracy_real)/2\n",
    "            \n",
    "            # train generator\n",
    "            latent_noise = self.sample_latent_space(image_generator.batch_size)\n",
    "\n",
    "            misleading_labels = np.ones((image_generator.batch_size, 1))\n",
    "            misleading_labels += .1 * np.random.normal(0, 1, misleading_labels.shape)\n",
    "\n",
    "            g_loss, g_accuracy = gan.train_on_batch(latent_noise, misleading_labels)\n",
    "            \n",
    "            d_loss_total += d_loss\n",
    "            g_loss_total += g_loss\n",
    "\n",
    "            if epoch + 1 < epochs_per_step:\n",
    "                self.__print_fit_progress(self.__steps[step], step, fade, epoch + 1, epochs_per_step, d_loss, g_loss)\n",
    "            else:\n",
    "                self.__print_fit_progress(self.__steps[step], step, fade, epoch + 1, epochs_per_step, d_loss_total/epochs_per_step, g_loss_total/epochs_per_step)\n",
    "\n",
    "            if tensorboard_callback is not None:\n",
    "                tensorboard_callback.on_epoch_end(\n",
    "                    epoch, step, fade,\n",
    "                    {'loss': {      #'d_loss_generated' : d_loss_generated,\n",
    "                                    #'d_loss_real' : d_loss_real,\n",
    "                                    'd_loss' : d_loss,\n",
    "                                    'g_loss': g_loss},\n",
    "                     'accuracy': {  #'d_accuracy_generated' : d_accuracy_generated,\n",
    "                                    #'d_accuracy_real' : d_accuracy_real,\n",
    "                                    'd_accuracy' : d_accuracy,\n",
    "                                    'g_accuracy': g_accuracy}})\n",
    "            \n",
    "            self.__total_epochs += 1\n",
    "    \n",
    "    def fit(self, image_generator : ImageGenerator, epochs_per_step : (int | list) =32, discriminator_train_per_gan_train=5, tensorboard_callback=None):\n",
    "        if isinstance(epochs_per_step, int):\n",
    "            epochs_per_step = [epochs_per_step for _ in range(len(self.__steps))]\n",
    "            \n",
    "        image_generator.set_images_size(self.__steps[0])\n",
    "        \n",
    "        self.__print_fit_progress_header()\n",
    "        self.__train_models(step=0, fade=False, image_generator=image_generator, epochs_per_step=epochs_per_step[0], discriminator_train_per_gan_train=discriminator_train_per_gan_train, tensorboard_callback=tensorboard_callback)\n",
    "\n",
    "        for step in range(1, len(self.__steps)):\n",
    "            img_size = self.__steps[step]\n",
    "            \n",
    "            image_generator.set_images_size(img_size)\n",
    "            \n",
    "            self.__train_models(step=step, fade=True, image_generator=image_generator, epochs_per_step=epochs_per_step[step], discriminator_train_per_gan_train=discriminator_train_per_gan_train, tensorboard_callback=tensorboard_callback)\n",
    "            \n",
    "            self.__train_models(step=step, fade=False, image_generator=image_generator, epochs_per_step=epochs_per_step[step], discriminator_train_per_gan_train=discriminator_train_per_gan_train, tensorboard_callback=tensorboard_callback)\n",
    "        \n",
    "        \n",
    "        if tensorboard_callback is not None:\n",
    "            tensorboard_callback.on_fit_end()\n",
    "    \n",
    "    def __print_fit_progress_header(self):\n",
    "        print('| image size       | step | fade | epoch            | time     | d_loss                           | g_loss                           |', end='')\n",
    "    \n",
    "    def __print_fit_progress(self, img_size, step, fade, epoch, total_epochs, d_loss, g_loss):\n",
    "        if epoch == 1:\n",
    "            self.__timer = perf_counter()\n",
    "            print()\n",
    "            \n",
    "        epoch_time = perf_counter() - self.__timer\n",
    "        \n",
    "        time = 0\n",
    "        if epoch == total_epochs:\n",
    "            # time passed\n",
    "            time = epoch_time\n",
    "        else:\n",
    "            # eta\n",
    "            time = epoch_time*(total_epochs - epoch)/epoch\n",
    "        \n",
    "        time_str = ''\n",
    "        if time < 60:\n",
    "            time_str = f'{int(time)}.{int(time*100)%100:02d}'\n",
    "        elif time < 60*60:\n",
    "            time_str = f'{(int(time)//60)%60}:{int(time)%60:02d}'\n",
    "        else:\n",
    "            time_str = f'{(int(time)//(60*60))%60}:{(int(time)//60)%60:02d}:{int(time)%60:02d}'\n",
    "        \n",
    "        img_size_str = ''\n",
    "        if fade:\n",
    "            img_size_str = f'{img_size//2} -> {img_size}'\n",
    "        else:\n",
    "            img_size_str = f'{img_size}'\n",
    "        \n",
    "        epoch_str = f'{epoch} / {total_epochs}'\n",
    "    \n",
    "        print(f'\\r| {img_size_str:>16s} | {step:4d} | {int(fade):4d} | {epoch_str:>16s} | {time_str:>8s} | {d_loss:32f} | {g_loss:32f} |', end='')\n",
    "\n",
    "    def __init_generator(self):\n",
    "        kernel_initializer = keras.initializers.HeNormal()\n",
    "        kernel_constraint = keras.constraints.MaxNorm(1.)\n",
    "        \n",
    "        self.__generator = []\n",
    "        \n",
    "        generator_input = x = Input((1, 1, self.__latent_dim))\n",
    "        \n",
    "        x = Conv2DTranspose(self.__latent_dim, 4, kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = PixelNormalization()(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "\n",
    "        x = Conv2D(self.__latent_dim, 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = PixelNormalization()(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "\n",
    "        output_size = 4\n",
    "\n",
    "        while output_size < self.__initial_image_size:\n",
    "            filters = self.__filters_count(output_size)\n",
    "\n",
    "            x = UpSampling2D()(x)\n",
    "            \n",
    "            x = Conv2DTranspose(filters, 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "            x = PixelNormalization()(x)\n",
    "            x = LeakyReLU(alpha=.2)(x)\n",
    "            \n",
    "            x = Conv2D(filters, 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "            x = PixelNormalization()(x)\n",
    "            x = LeakyReLU(alpha=.2)(x)\n",
    "\n",
    "            output_size <<= 1\n",
    "\n",
    "        x = Conv2D(self.__image_channels, 1, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        \n",
    "        generator = keras.Model(generator_input, x, name=f'generator_{self.__initial_image_size:}x{self.__initial_image_size:}')\n",
    "\n",
    "        self.__generator.append([generator, generator])\n",
    "        \n",
    "        for _ in range(1, len(self.__steps)):\n",
    "            next_generators = self.__add_generator_block(self.__generator[-1][0])\n",
    "            self.__generator.append(next_generators)\n",
    "    \n",
    "    def __add_generator_block(self, generator : keras.Model):\n",
    "        kernel_initializer = keras.initializers.HeNormal()\n",
    "        kernel_constraint = keras.constraints.MaxNorm(1.)\n",
    "        \n",
    "        prev_block_end = generator.layers[-2].output\n",
    "        \n",
    "        upsampling = x = UpSampling2D()(prev_block_end)\n",
    "        \n",
    "        output_image_size = x.shape[1]\n",
    "        filters = self.__filters_count(output_image_size)\n",
    "        \n",
    "        x = Conv2D(filters, 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = PixelNormalization()(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "\n",
    "        x = Conv2D(filters, 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = PixelNormalization()(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        new_generator_output = Conv2D(self.__image_channels, 1, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        \n",
    "        new_generator = keras.Model(generator.input, new_generator_output, name=f'generator_{output_image_size}x{output_image_size}')\n",
    "        \n",
    "        generator_output = generator.layers[-1]\n",
    "        generator_output_upscaled = generator_output(upsampling)\n",
    "        \n",
    "        combined = WeightedSum()((new_generator_output, generator_output_upscaled))\n",
    "        \n",
    "        new_generator_fade = keras.Model(generator.input, combined, name=f'generator_fade_{output_image_size}x{output_image_size}')\n",
    "        \n",
    "        return (new_generator, new_generator_fade)\n",
    "\n",
    "    def __init_discriminator(self):\n",
    "        kernel_initializer = keras.initializers.HeNormal()\n",
    "        kernel_constraint = keras.constraints.MaxNorm(1.)\n",
    "        \n",
    "        self.__discriminator = []\n",
    "        \n",
    "        discriminator_input = x = Input((self.__initial_image_size, self.__initial_image_size, self.__image_channels))\n",
    "\n",
    "        x = Conv2D(self.__filters_count(self.__initial_image_size << 1), 1, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "\n",
    "        output_size = self.__initial_image_size\n",
    "\n",
    "        while output_size > 4:\n",
    "            x = Conv2D(self.__filters_count(output_size << 1), 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "            x = LeakyReLU(alpha=.2)(x)\n",
    "            \n",
    "            x = Conv2D(self.__filters_count(output_size), 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "            x = LeakyReLU(alpha=.2)(x)\n",
    "            \n",
    "            x = AveragePooling2D()(x)\n",
    "\n",
    "            output_size >>= 1\n",
    "\n",
    "        x = MinibatchStdev()(x)\n",
    "        \n",
    "        x = Conv2D(self.__filters_count(output_size), 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        x = Conv2D(self.__latent_dim, 4, kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        x = Dense(1)(x)\n",
    "\n",
    "        discriminator = keras.Model(discriminator_input, x, name=f'discriminator_{self.__initial_image_size}x{self.__initial_image_size}')\n",
    "        \n",
    "        discriminator.compile(optimizer=self.__discriminator_optimizer, loss=wasserstein_loss, metrics=['accuracy'])\n",
    "        \n",
    "        self.__discriminator.append((discriminator, discriminator))\n",
    "\n",
    "        for _ in range(1, len(self.__steps)):\n",
    "            next_discriminators = self.__add_discriminator_block(self.__discriminator[-1][0])\n",
    "            self.__discriminator.append(next_discriminators)\n",
    "    \n",
    "    def __add_discriminator_block(self, discriminator : keras.Model):\n",
    "        kernel_initializer = keras.initializers.HeNormal()\n",
    "        kernel_constraint = keras.constraints.MaxNorm(1.)\n",
    "        \n",
    "        discriminator_input_shape = discriminator.input.shape\n",
    "        new_discriminator_input_shape = (discriminator_input_shape[-3] << 1, discriminator_input_shape[-2] << 1, discriminator_input_shape[-1])\n",
    "        output_image_size = new_discriminator_input_shape[0]\n",
    "        \n",
    "        new_discriminator_input = x = Input(shape=new_discriminator_input_shape)\n",
    "        \n",
    "        x = Conv2D(self.__filters_count(output_image_size << 1), 1, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        x = Conv2D(self.__filters_count(output_image_size << 1), 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        x = Conv2D(self.__filters_count(output_image_size), 3, padding='same', kernel_initializer=kernel_initializer, kernel_constraint=kernel_constraint)(x)\n",
    "        x = LeakyReLU(alpha=.2)(x)\n",
    "        \n",
    "        new_block_end = x = AveragePooling2D()(x)\n",
    "        \n",
    "        # skip the input, 1x1 and activation layers of the old model\n",
    "        for i in range(3, len(discriminator.layers)):\n",
    "            x = discriminator.layers[i](x)\n",
    "            \n",
    "        new_discriminator = keras.Model(new_discriminator_input, x, name=f'discriminator_{output_image_size}x{output_image_size}')\n",
    "        \n",
    "        new_discriminator.compile(optimizer=self.__discriminator_optimizer, loss=wasserstein_loss, metrics=['accuracy'])\n",
    "        \n",
    "        x = AveragePooling2D()(new_discriminator_input)\n",
    "        x = discriminator.layers[1](x)  # 1x1 conv\n",
    "        x = discriminator.layers[2](x)  # activation\n",
    "        \n",
    "        x = WeightedSum()([new_block_end, x])\n",
    "        \n",
    "        # same as above\n",
    "        for i in range(3, len(discriminator.layers)):\n",
    "            x = discriminator.layers[i](x)\n",
    "            \n",
    "        new_discriminator_fade = keras.Model(new_discriminator_input, x, name=f'discriminator_fade_{output_image_size}x{output_image_size}')\n",
    "        \n",
    "        new_discriminator_fade.compile(optimizer=self.__discriminator_optimizer, loss=wasserstein_loss, metrics=['accuracy'])\n",
    "        \n",
    "        return (new_discriminator, new_discriminator_fade)\n",
    "            \n",
    "    \n",
    "    def __init_gan(self):\n",
    "        self.__gan = []\n",
    "        \n",
    "        for generators, discirminators in zip(self.__generator, self.__discriminator):\n",
    "            # straight-through model\n",
    "            discirminators[0].trainable = False\n",
    "            \n",
    "            gan = keras.Sequential(name=f'gan_{generators[0].output.shape[1]}x{generators[0].output.shape[1]}')\n",
    "            gan.add(generators[0])\n",
    "            gan.add(discirminators[0])\n",
    "            \n",
    "            gan.compile(loss=wasserstein_loss, optimizer=self.__gan_optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            # fade-in model\n",
    "            discirminators[1].trainable = False\n",
    "            \n",
    "            gan_fade = keras.Sequential(name=f'gan_fade_{generators[0].output.shape[1]}x{generators[0].output.shape[1]}')\n",
    "            gan_fade.add(generators[1])\n",
    "            gan_fade.add(discirminators[1])\n",
    "            \n",
    "            gan_fade.compile(loss=wasserstein_loss, optimizer=self.__gan_optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            self.__gan.append((gan, gan_fade))\n",
    "\n",
    "    def __filters_count(self, output_size):\n",
    "        filters = self.__latent_dim\n",
    "        while output_size*filters >= self.__final_image_size*16:\n",
    "            filters //= 2\n",
    "        \n",
    "        return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix write_model_summary\n",
    "class TensorBoardCallback(object):\n",
    "    def __init__(self, logdir : str, model : ProgressiveGAN = None, metrics_save_interval : int =20, generator_preview_save_interval : int =100):\n",
    "        self.__datetime_str = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        try:\n",
    "            os.mkdir(os.path.join('gen', self.__datetime_str))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.__logdir = os.path.join(logdir, self.__datetime_str)\n",
    "        self.__model = model\n",
    "        self.__metrics_save_interval = metrics_save_interval\n",
    "        self.__generator_preview_save_interval = generator_preview_save_interval\n",
    "        \n",
    "        self.__generator_preview_vid_latent = model.sample_latent_space(1)\n",
    "        self.__generator_preview_vid = cv2.VideoWriter(os.path.join('./gen', self.__datetime_str, 'generator_preview.mp4'), 0x7634706d, 60.0, (64, 64))\n",
    "        \n",
    "        self.__total_epochs = 0\n",
    "        \n",
    "        self.__writers = {}\n",
    "        \n",
    "        self.__metrics_interval = {}\n",
    "        self.__metrics_interval_count = 0\n",
    "\n",
    "        if model is not None:\n",
    "            self.__preview_latent_noise = model.sample_latent_space(4)\n",
    "    \n",
    "    def on_epoch_end(self, epoch : int, step : int, fade : bool, metrics_dict : dict):\n",
    "        self.__total_epochs += 1\n",
    "        \n",
    "        for metric_name, metric_dict in metrics_dict.items():\n",
    "            if metric_name not in self.__metrics_interval.keys():\n",
    "                self.__metrics_interval[metric_name] = {}\n",
    "                \n",
    "            for metric_subname, metric_value in metric_dict.items():\n",
    "                if metric_subname not in self.__metrics_interval[metric_name].keys():\n",
    "                    self.__metrics_interval[metric_name][metric_subname] = .0\n",
    "            \n",
    "                self.__metrics_interval[metric_name][metric_subname] += metric_value\n",
    "            \n",
    "        self.__metrics_interval_count += 1\n",
    "        \n",
    "        if self.__total_epochs % self.__metrics_save_interval == 0:\n",
    "            self.__write_metrics()\n",
    "            self.__metrics_interval_count = 0\n",
    "            self.__metrics_interval = {}\n",
    "        \n",
    "        if self.__total_epochs % self.__generator_preview_save_interval == 0:\n",
    "            self.__write_generator_preview(step, fade)\n",
    "        \n",
    "        if self.__total_epochs % 100 == 0:\n",
    "            frame = self.__model.generator[step][int(fade)].predict(self.__generator_preview_vid_latent)[0]\n",
    "            # [-1., 1.] -> [0, 255]\n",
    "            frame = np.clip((frame + 1.)*127.5, 0, 255).astype(np.uint8)\n",
    "            frame = cv2.resize(frame, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "            if len(frame.shape) == 2:\n",
    "                frame = frame[:,:,np.newaxis]\n",
    "            if frame.shape[2] == 1:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "                \n",
    "            self.__generator_preview_vid.write(frame)\n",
    "            \n",
    "            if self.__total_epochs % 1000 == 0:\n",
    "                cv2.imwrite(os.path.join('./gen', self.__datetime_str , f'{step:02d}_{epoch:06d}_{int(fade)}.jpg'), frame)\n",
    "        \n",
    "    def on_fit_end(self):\n",
    "        self.__generator_preview_vid.release()\n",
    "        \n",
    "        for _, writer in self.__writers.items():\n",
    "            writer.close()\n",
    "        \n",
    "        self.__writers = {}\n",
    "        \n",
    "    def __write_metrics(self):\n",
    "        for metric_name, metric_dict in self.__metrics_interval.items():\n",
    "            for loss_name, loss_value in metric_dict.items():\n",
    "                if os.path.join(self.__logdir, loss_name) not in self.__writers.keys():\n",
    "                    writer = tf.summary.create_file_writer(os.path.join(self.__logdir, loss_name))\n",
    "                    self.__writers[os.path.join(self.__logdir, loss_name)] = writer\n",
    "                    \n",
    "                with self.__writers[os.path.join(self.__logdir, loss_name)].as_default():\n",
    "                    tf.summary.scalar(metric_name, loss_value/self.__metrics_interval_count, step=self.__total_epochs)\n",
    "    \n",
    "    def __write_generator_preview(self, step : int, fade : bool):\n",
    "        if os.path.join(self.__logdir, 'model') not in self.__writers.keys():\n",
    "            writer = tf.summary.create_file_writer(os.path.join(self.__logdir, 'model'))\n",
    "            self.__writers[os.path.join(self.__logdir, 'model')] = writer\n",
    "            \n",
    "        with self.__writers[os.path.join(self.__logdir, 'model')].as_default():\n",
    "            preview_generated_images = self.__model.generator[step][fade].predict(self.__preview_latent_noise)\n",
    "            tf.summary.image('Generator preview', preview_generated_images[:4,], step=step, max_outputs=4)\n",
    "    \n",
    "    def __del__(self):\n",
    "        for _, writer in self.__writers.items():\n",
    "            writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageGenerator(r'E:\\Workspace\\datasets\\cats\\train', batch_size=16, image_channels=3) # r'E:\\Workspace\\datasets\\b\\train_1\\512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-5, beta_1=0., beta_2=.99, epsilon=1e-8)\n",
    "# optimizer = keras.optimizers.RMSprop(learning_rate=5e-5)\n",
    "\n",
    "progan = ProgressiveGAN(\n",
    "    latent_dim=256,\n",
    "    initial_image_size=4,\n",
    "    final_image_size=512,\n",
    "    image_channels=3,\n",
    "    discriminator_optimizer=optimizer,\n",
    "    gan_optimizer=optimizer)\n",
    "\n",
    "tensorboard_callback = TensorBoardCallback('./logs', progan)\n",
    "\n",
    "progan.fit(img_gen, epochs_per_step=400, discriminator_train_per_gan_train=1, tensorboard_callback=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = np.concatenate([img_gen.get_batch(), img_gen.get_batch()], axis=0)\n",
    "print(batch.shape)\n",
    "print(batch.min())\n",
    "print(batch.max())\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.imshow(np.vstack([np.hstack([batch[i + 8*j] for i in range(8)]) for j in range(4)])/2 + .5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_noise = progan.sample_latent_space(8)\n",
    "\n",
    "generated_images = np.zeros((8*len(progan.generator), 32, 32, 3))\n",
    "for i in range(len(progan.generator)):\n",
    "    g = progan.generator[i][0].predict(latent_noise)\n",
    "    for j in range(8):\n",
    "        img = g[j,]\n",
    "        img = (img + 1.)/2.\n",
    "        generated_images[8*i + j,] = cv2.resize(img, (32, 32), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "print(generated_images.shape)\n",
    "print(generated_images.min())\n",
    "print(generated_images.max())\n",
    "\n",
    "plt.figure(figsize=(16, 2*len(progan.generator)))\n",
    "\n",
    "plt.imshow(np.vstack([np.hstack([generated_images[i + 8*j] for i in range(8)]) for j in range(len(progan.generator))])/2 + .5, interpolation=None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progan.generator[-1][0].save('./model/generator_cats.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
