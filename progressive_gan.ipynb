{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.ops import summary_ops_v2\n",
    "from tensorflow.python.keras.callbacks import keras_model_summary\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Input, Dense, Flatten, Dropout, Concatenate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combine(keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Combine, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = self.add_weight(shape=(1,), initializer=\"zeros\", trainable=False)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Combine, self).get_config().copy()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.alpha*inputs[0] + (1 - self.alpha)*inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStdev(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "\n",
    "    # calculate the mean standard deviation across each pixel coord\n",
    "    def call(self, inputs):\n",
    "        mean = keras.backend.mean(inputs, axis=0, keepdims=True)\n",
    "        mean_sq_diff = keras.backend.mean(keras.backend.square(inputs - mean), axis=0, keepdims=True) + 1e-8\n",
    "        mean_pix = keras.backend.mean(keras.backend.sqrt(mean_sq_diff), keepdims=True)\n",
    "        shape = keras.backend.shape(inputs)\n",
    "        output = keras.backend.tile(mean_pix, [shape[0], shape[1], shape[2], 1])\n",
    "        return keras.backend.concatenate([inputs, output], axis=-1)\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[-1] += 1\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(object):\n",
    "    def __init__(self, images_folder_path, initial_images_size=4):\n",
    "        self.__images_folder_path = images_folder_path\n",
    "        self.__images_size = initial_images_size\n",
    "        self.__filenames = []\n",
    "\n",
    "        for _, _, fnames in os.walk(self.__images_folder_path):\n",
    "            for fname in fnames:\n",
    "                if fname.split('.')[-1] in ('jpg', 'jpeg'):\n",
    "                    self.__filenames.append(fname)\n",
    "            break\n",
    "    \n",
    "        print(f'Loaded {len(self.__filenames)} images.')\n",
    "    \n",
    "    def set_images_size(self, size):\n",
    "        self.__images_size = size\n",
    "\n",
    "    def get_batch(self, batch_size=32):\n",
    "        result = np.zeros((batch_size, self.__images_size, self.__images_size, 3))\n",
    "\n",
    "        fnames = sample(self.__filenames, batch_size)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            img = cv2.imread(os.path.join(self.__images_folder_path, fnames[i]))[:,:,::-1]\n",
    "            min_size = min(img.shape[:2])\n",
    "            img = img[(img.shape[0] - min_size)//2:(img.shape[0] + min_size)//2,\n",
    "                      (img.shape[1] - min_size)//2:(img.shape[1] + min_size)//2]\n",
    "            img = cv2.resize(img, (self.__images_size,)*2).astype(np.float32)\n",
    "            img -= img.min()\n",
    "            img /= img.max()\n",
    "            # [0, 1] -> [-1, 1]\n",
    "            img *= 2.\n",
    "            img -= 1.\n",
    "            result[i,] = img\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_layer(layer):\n",
    "    config = layer.get_config()\n",
    "    del config['name']\n",
    "    weights = layer.get_weights()\n",
    "    cloned_layer = type(layer).from_config(config)\n",
    "    cloned_layer.build(layer.input_shape)\n",
    "    cloned_layer.set_weights(weights)\n",
    "    return cloned_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveGAN(object):\n",
    "    __latent_dim            : int\n",
    "    __initial_image_size    : int\n",
    "    __final_image_size      : int\n",
    "    __current_image_size    : int\n",
    "\n",
    "    __generator             : keras.Model\n",
    "    __discriminator         : keras.Model\n",
    "\n",
    "    __gan                   : keras.Model\n",
    "\n",
    "    def __init__(self, latent_dim : int =128, initial_image_size : int =4, final_image_size : int =512, gan_optimizer : (str | keras.optimizers.Optimizer) ='adam', discriminator_optimizer : (str | keras.optimizers.Optimizer) ='adam'):\n",
    "        self.__latent_dim = latent_dim\n",
    "        self.__initial_image_size = initial_image_size\n",
    "        self.__final_image_size = final_image_size\n",
    "        self.__gan_optimizer = gan_optimizer\n",
    "        self.__discriminator_optimizer = discriminator_optimizer\n",
    "\n",
    "        self.__current_image_size = self.__initial_image_size\n",
    "\n",
    "        self.__generator = None\n",
    "        self.__discriminator = None\n",
    "        self.__gan = None\n",
    "\n",
    "        self.__init_generator()\n",
    "        self.__init_discriminator()\n",
    "        self.__init_gan()\n",
    "    \n",
    "    @property\n",
    "    def generator(self):\n",
    "        return self.__generator\n",
    "\n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        return self.__discriminator\n",
    "\n",
    "    @property\n",
    "    def gan(self):\n",
    "        return self.__gan\n",
    "\n",
    "    def fit(self, image_generator : ImageGenerator, epochs_per_step=32, batch_size=32, discriminator_train_per_gan_train=5, tensorboard_callback=None):\n",
    "        \n",
    "        step = 0\n",
    "        epochs_per_half_step = epochs_per_step >> 1\n",
    "\n",
    "        if tensorboard_callback is not None:\n",
    "            tensorboard_callback.write_model_summary(step=step)\n",
    "        \n",
    "        combines_dropped = True\n",
    "\n",
    "        while True:\n",
    "            print(f'img size={self.__current_image_size}  ')\n",
    "\n",
    "            image_generator.set_images_size(self.__current_image_size)\n",
    "\n",
    "            for epoch in range(epochs_per_step):\n",
    "                # increasing image size\n",
    "                if epoch == epochs_per_step >> 1 and self.__current_image_size < self.__final_image_size:\n",
    "                    print(f'\\nimg size={self.__current_image_size} -> ', end='')\n",
    "\n",
    "                    cv2.imwrite(f'./gen/{self.__current_image_size}.png', np.clip((generated_images[0] * 255), 0, 255).astype(np.uint8))\n",
    "\n",
    "                    generator_combine, discriminator_combine = self.__increase_image_size()\n",
    "                    combines_dropped = False\n",
    "                    image_generator.set_images_size(self.__current_image_size)\n",
    "\n",
    "                    print(f'{self.__current_image_size}  ')\n",
    "\n",
    "                    if tensorboard_callback is not None:\n",
    "                        tensorboard_callback.write_model_summary(step=step*10 + 1)\n",
    "\n",
    "                # adjust combine param\n",
    "                if not combines_dropped:\n",
    "                    alpha = float(epoch - (epochs_per_step >> 1))/(epochs_per_step >> 1)\n",
    "                    generator_combine.set_weights([np.array([alpha])])\n",
    "                    discriminator_combine.set_weights([np.array([alpha])])\n",
    "\n",
    "                    print(f' alpha={generator_combine.get_weights()[0]}  ', end='')\n",
    "\n",
    "                # train discriminator\n",
    "                d_loss = 0.\n",
    "                for _ in range(discriminator_train_per_gan_train):\n",
    "                    latent_noise = np.random.normal(0, 1, (batch_size, 1, 1, self.__latent_dim))\n",
    "\n",
    "                    generated_images = self.__generator.predict(latent_noise)\n",
    "                    real_images = image_generator.get_batch(batch_size)\n",
    "                    \n",
    "                    generated_labels = np.zeros((batch_size, 1))\n",
    "                    real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "                    # combined_images = np.concatenate([generated_images, real_images])\n",
    "\n",
    "                    # labels = np.ones((batch_size << 1, 1))\n",
    "                    # labels[:batch_size,] = 0\n",
    "\n",
    "                    generated_labels += 0.1 * np.random.random(generated_labels.shape)\n",
    "                    generated_labels = np.clip(generated_labels, 0, 1)\n",
    "\n",
    "                    real_labels += 0.1 * np.random.random(real_labels.shape)\n",
    "                    real_labels = np.clip(real_labels, 0, 1)\n",
    "                    \n",
    "                    d_loss += self.__discriminator.train_on_batch(generated_images, generated_labels)\n",
    "                    d_loss += self.__discriminator.train_on_batch(real_images, real_labels)\n",
    "                \n",
    "                d_loss /= discriminator_train_per_gan_train\n",
    "                \n",
    "                # train generator\n",
    "                latent_noise = np.random.normal(0, 1, (batch_size, 1, 1, self.__latent_dim))\n",
    "\n",
    "                misleading_targets = np.ones((batch_size, 1))\n",
    "\n",
    "                g_loss = self.__gan.train_on_batch(latent_noise, misleading_targets)\n",
    "\n",
    "                print(f'\\r{epoch + 1} / {epochs_per_step} d_loss={d_loss} g_loss={g_loss}', end='')\n",
    "\n",
    "                if tensorboard_callback is not None:\n",
    "                    tensorboard_callback.write_losses(d_loss, g_loss, step=(epoch + step*epochs_per_step))\n",
    "            \n",
    "            print()\n",
    "\n",
    "            if tensorboard_callback is not None:\n",
    "                tensorboard_callback.write_generator_preview(step=step)\n",
    "\n",
    "            # final size reached\n",
    "            if self.__current_image_size == self.__final_image_size and combines_dropped:\n",
    "                break\n",
    "            \n",
    "            self.__drop_combine_layer()\n",
    "            combines_dropped = True\n",
    "            \n",
    "            if tensorboard_callback is not None:\n",
    "                tensorboard_callback.write_model_summary(step=step*10)\n",
    "\n",
    "            step += 1\n",
    "        \n",
    "        print()\n",
    "\n",
    "        cv2.imwrite(f'./gen/{self.__current_image_size}.png', np.clip((generated_images[0] * 255), 0, 255).astype(np.uint8))\n",
    "\n",
    "    def __init_generator(self) -> keras.Model:\n",
    "        generator_input = x = Input((1, 1, self.__latent_dim))\n",
    "\n",
    "        x = Conv2DTranspose(self.__latent_dim, 4, activation='relu')(x)\n",
    "        x = Conv2D(self.__latent_dim, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "        output_size = 4\n",
    "\n",
    "        while output_size < self.__initial_image_size:\n",
    "            filters = self.__filters_count(output_size)\n",
    "\n",
    "            x = UpSampling2D()(x)\n",
    "            x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "            x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "            output_size <<= 1\n",
    "\n",
    "        x = Conv2D(3, 1, padding='same', activation='tanh')(x)\n",
    "\n",
    "        self.__generator = keras.Model(generator_input, x, name='generator')\n",
    "\n",
    "    def __init_discriminator(self) -> keras.Model:\n",
    "        discriminator_input = x = Input((self.__initial_image_size, self.__initial_image_size, 3))\n",
    "\n",
    "        x = Conv2D(self.__filters_count(self.__initial_image_size << 1), 1, padding='same', activation='relu')(x)\n",
    "\n",
    "        output_size = self.__initial_image_size\n",
    "\n",
    "        while output_size > 4:\n",
    "            x = Conv2D(self.__filters_count(output_size << 1), 3, padding='same', activation='relu')(x)\n",
    "            x = Conv2D(self.__filters_count(output_size), 3, padding='same', activation='relu')(x)\n",
    "            x = MaxPool2D()(x)\n",
    "\n",
    "            output_size >>= 1\n",
    "\n",
    "        x = MinibatchStdev()(x)\n",
    "        x = Conv2D(self.__filters_count(output_size), 3, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(self.__latent_dim, 4, activation='relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        self.__discriminator = keras.Model(discriminator_input, x, name='discriminator')\n",
    "\n",
    "        self.__compile_discriminator()\n",
    "    \n",
    "    def __init_gan(self):\n",
    "        gan_input = x = Input((1, 1, self.__latent_dim))\n",
    "\n",
    "        self.__discriminator.trainable = False\n",
    "        self.__gan = keras.Model(gan_input, self.__discriminator(self.__generator(gan_input)), name='gan')\n",
    "\n",
    "        self.__gan.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4, clipvalue=1.0, decay=1e-8), loss='binary_crossentropy')\n",
    "    \n",
    "    def __increase_image_size(self):\n",
    "        self.__current_image_size <<= 1\n",
    "\n",
    "        # generator\n",
    "\n",
    "        # new layers\n",
    "        x = UpSampling2D()(self.__generator.layers[-2].output)\n",
    "        x = Conv2D(self.__filters_count(self.__current_image_size), 3, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(self.__filters_count(self.__current_image_size), 3, padding='same', activation='relu')(x)\n",
    "\n",
    "        x = Conv2D(3, 1, padding='same', activation='tanh')(x)\n",
    "\n",
    "        # upsample previous output\n",
    "        prev_step_output = self.__generator.output\n",
    "        prev_step_rgb = keras.layers.UpSampling2D()(prev_step_output)\n",
    "\n",
    "        generator_combine = Combine(name='generator_combine')\n",
    "        x = generator_combine([x, prev_step_rgb])\n",
    "\n",
    "        self.__generator = keras.Model(self.__generator.input, x, name='generator')\n",
    "\n",
    "        # discriminator\n",
    "        discriminator_input = Input((self.__current_image_size, self.__current_image_size, 3))\n",
    "\n",
    "        prev_step_downsample = MaxPool2D()(discriminator_input)\n",
    "\n",
    "        prev_step_rgb = self.__discriminator.layers[1](prev_step_downsample)\n",
    "\n",
    "        x = Conv2D(self.__filters_count(self.__current_image_size << 1), 1, padding='same', activation='relu')(x)\n",
    "\n",
    "        x = Conv2D(self.__filters_count(self.__current_image_size << 1), 3, padding='same', activation='relu')(discriminator_input)\n",
    "        x = Conv2D(self.__filters_count(self.__current_image_size), 3, padding='same', activation='relu')(x)\n",
    "        new_step_output = MaxPool2D()(x)\n",
    "\n",
    "        discriminator_combine = Combine(name='discriminator_combine')\n",
    "        x = discriminator_combine([new_step_output, prev_step_rgb])\n",
    "        \n",
    "        for layer in self.__discriminator.layers[2:]:\n",
    "            x = clone_layer(layer)(x)\n",
    "\n",
    "        self.__discriminator = keras.Model(discriminator_input, x, name='discriminator')\n",
    "\n",
    "        self.__compile_discriminator()\n",
    "\n",
    "        # gan\n",
    "        self.__init_gan()\n",
    "\n",
    "        return generator_combine, discriminator_combine\n",
    "    \n",
    "    def __drop_combine_layer(self):\n",
    "        # generator\n",
    "        layer = self.__generator.layers[0]\n",
    "\n",
    "        layers = []\n",
    "        i = -1\n",
    "        s = self.__initial_image_size\n",
    "        while s < self.__current_image_size:\n",
    "            s <<= 1\n",
    "            i += 1\n",
    "\n",
    "        while True:\n",
    "            layer = layer._outbound_nodes[0].layer\n",
    "            layers.append(layer)\n",
    "            if len(set(map(lambda x: x.layer.name, layer._outbound_nodes))) != 1:\n",
    "                break\n",
    "                # if i == 0:\n",
    "                #     break\n",
    "                # i -= 1\n",
    "\n",
    "        outs = list(set(layer._outbound_nodes))\n",
    "\n",
    "        layer_a = outs[0].layer\n",
    "        layer_b = outs[1].layer\n",
    "\n",
    "        branch_a = [layer_a]\n",
    "        branch_b = [layer_b]\n",
    "        \n",
    "        while len(layer_a._outbound_nodes) > 0:\n",
    "            layer_a = layer_a._outbound_nodes[0].layer\n",
    "            branch_a.append(layer_a)\n",
    "        \n",
    "        while len(layer_b._outbound_nodes) > 0:\n",
    "            layer_b = layer_b._outbound_nodes[0].layer\n",
    "            branch_b.append(layer_b)\n",
    "\n",
    "        if len(branch_a) > len(branch_b):\n",
    "            layers.extend(branch_a)\n",
    "            \n",
    "        else:\n",
    "            layers.extend(branch_b)\n",
    "\n",
    "        generator_input = x = keras.layers.Input(shape=self.__generator.input.shape[1:])\n",
    "        for layer in layers:\n",
    "            if 'combine' in layer.name:\n",
    "                break\n",
    "            x = clone_layer(layer)(x)\n",
    "\n",
    "        self.__generator = keras.Model(generator_input, x, name='generator')\n",
    "\n",
    "        # discirminator\n",
    "        layer = self.__discriminator.layers[0]\n",
    "\n",
    "        layer_a = layer._outbound_nodes[0].layer\n",
    "        layer_b = layer._outbound_nodes[1].layer\n",
    "\n",
    "        branch_a = [layer_a]\n",
    "        branch_b = [layer_b]\n",
    "        \n",
    "        while len(layer_a._outbound_nodes) > 0:\n",
    "            layer_a = layer_a._outbound_nodes[0].layer\n",
    "            branch_a.append(layer_a)\n",
    "        \n",
    "        while len(layer_b._outbound_nodes) > 0:\n",
    "            layer_b = layer_b._outbound_nodes[0].layer\n",
    "            branch_b.append(layer_b)\n",
    "\n",
    "        if len(branch_a) > len(branch_b):\n",
    "            layers = branch_a\n",
    "            \n",
    "        else:\n",
    "            layers = branch_b\n",
    "\n",
    "        discriminator_input = x = keras.layers.Input(self.__discriminator.input.shape[1:])\n",
    "        for layer in layers:\n",
    "            if 'combine' in layer.name:\n",
    "                continue\n",
    "            x = clone_layer(layer)(x)\n",
    "\n",
    "        self.__discriminator = keras.Model(discriminator_input, x, name='discriminator')\n",
    "\n",
    "        self.__compile_discriminator()\n",
    "        \n",
    "        # gan\n",
    "        self.__init_gan()\n",
    "    \n",
    "    def __compile_discriminator(self):\n",
    "        self.__discriminator.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-4, clipvalue=1.0, decay=1e-8), loss='binary_crossentropy')\n",
    "\n",
    "    def __filters_count(self, output_size):\n",
    "        filters = self.__latent_dim\n",
    "        while output_size*filters >= self.__final_image_size*16:\n",
    "            filters //= 2\n",
    "        \n",
    "        return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorBoardCallback(object):\n",
    "    def __init__(self, logdir : str, model : ProgressiveGAN = None):\n",
    "        self.__logdir = logdir\n",
    "\n",
    "        self.__discriminator_writer = tf.summary.create_file_writer(os.path.join(logdir, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'), 'discriminator'))\n",
    "        self.__gan_writer = tf.summary.create_file_writer(os.path.join(logdir, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'), 'gan'))\n",
    "        self.__model_writer = tf.summary.create_file_writer(os.path.join(logdir, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'), 'model'))\n",
    "\n",
    "        self.__model = model\n",
    "        if model is not None:\n",
    "            self.__preview_latent_noise = np.random.normal(0, 1, (4, *model.generator.input.shape[1:]))\n",
    "    \n",
    "    def write_losses(self, d_loss, g_loss, step):\n",
    "        with self.__discriminator_writer.as_default():\n",
    "            tf.summary.scalar('loss', d_loss, step=step)\n",
    "        with self.__gan_writer.as_default():\n",
    "            tf.summary.scalar('loss', -g_loss, step=step)\n",
    "    \n",
    "    def write_generator_preview(self, step):\n",
    "        with self.__gan_writer.as_default():\n",
    "            preview_generated_images = self.__model.generator.predict(self.__preview_latent_noise)\n",
    "            tf.summary.image('Generator preview', preview_generated_images[:4,], step=step, max_outputs=4)\n",
    "    \n",
    "    def write_model_summary(self, step):\n",
    "        with self.__model_writer.as_default():\n",
    "            with summary_ops_v2.record_if(True):\n",
    "                if self.__model.gan._is_graph_network:\n",
    "                    keras_model_summary('gan', self.__model.gan, step=step)\n",
    "\n",
    "                if self.__model.generator._is_graph_network:\n",
    "                    keras_model_summary('generator', self.__model.generator, step=step)\n",
    "\n",
    "                if self.__model.discriminator._is_graph_network:\n",
    "                    keras_model_summary('discriminator', self.__model.discriminator, step=step)\n",
    "                    \n",
    "                gan_train_fn = self.__model.gan.train_tf_function\n",
    "                if hasattr(gan_train_fn, 'function_spec'):\n",
    "                    summary_ops_v2.graph(gan_train_fn._concrete_stateful_fn.graph)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.__discriminator_writer.close()\n",
    "        self.__gan_writer.close()\n",
    "        self.__model_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9993 images.\n"
     ]
    }
   ],
   "source": [
    "img_gen = ImageGenerator(r'E:\\Workspace\\datasets\\cats') # (r'E:\\Workspace\\datasets\\b\\train_1\\512') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img size=4  \n",
      "200 / 400 d_loss=0.21217384043666243 g_loss=3.4416749477386475\n",
      "img size=4 -> 8  \n",
      "400 / 400 d_loss=0.26689958949873466 g_loss=2.642033100128174 alpha=[0.995]   \n",
      "img size=8  \n",
      "200 / 400 d_loss=19.49173406461549 g_loss=5.8443516692818775e-099\n",
      "img size=8 -> 16  \n",
      "400 / 400 d_loss=25.836608615367055 g_loss=40.052955627441406lpha=[0.995]  ]     \n",
      "img size=16  \n",
      "107 / 400 d_loss=37.891128182411194 g_loss=7.695806214513823e-109"
     ]
    }
   ],
   "source": [
    "progan = ProgressiveGAN(latent_dim=128, initial_image_size=4, final_image_size=512)\n",
    "\n",
    "tensorboard_callback = TensorBoardCallback('./logs', progan)\n",
    "\n",
    "progan.fit(img_gen, epochs_per_step=400, batch_size=32, discriminator_train_per_gan_train=4, tensorboard_callback=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = img_gen.get_batch()\n",
    "print(batch.shape)\n",
    "print(batch.min())\n",
    "print(batch.max())\n",
    "\n",
    "plt.figure(figsize=(64, 8))\n",
    "\n",
    "plt.imshow(np.vstack([np.hstack([batch[i + 8*j] for i in range(8)]) for j in range(4)]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_noise = np.random.normal(0, 1, (32, 1, 1, 512))\n",
    "\n",
    "generated_images = progan.generator.predict(latent_noise)\n",
    "print(generated_images.min())\n",
    "print(generated_images.max())\n",
    "\n",
    "plt.figure(figsize=(64, 8))\n",
    "\n",
    "plt.imshow(np.vstack([np.hstack([generated_images[i + 8*j] for i in range(8)]) for j in range(4)]))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
