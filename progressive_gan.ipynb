{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Input, Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Combine(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Combine, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = tf.Variable(initial_value=tf.zeros_initializer()(shape=(1,), dtype=\"float32\"), trainable=False)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Combine, self).get_config().copy()\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.alpha*inputs[0] + (1 - self.alpha)*inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGenerator(object):\n",
    "    def __init__(self, images_folder_path, initial_images_size=4, batch_size=16):\n",
    "        self.__images_folder_path = images_folder_path\n",
    "        self.__images_size = initial_images_size\n",
    "        self.__batch_size = batch_size\n",
    "        self.__filenames = []\n",
    "\n",
    "        for _, _, fnames in os.walk(self.__images_folder_path):\n",
    "            for fname in fnames:\n",
    "                if fname.split('.')[-1] in ('jpg', 'jpeg'):\n",
    "                    self.__filenames.append(fname)\n",
    "            break\n",
    "    \n",
    "        print(f'Loaded {len(self.__filenames)} images.')\n",
    "    \n",
    "    def set_images_size(self, size):\n",
    "        self.__images_size = size\n",
    "\n",
    "    def get_batch(self):\n",
    "        result = np.zeros((self.__batch_size, self.__images_size, self.__images_size, 3))\n",
    "\n",
    "        fnames = sample(self.__filenames, self.__batch_size)\n",
    "\n",
    "        for i in range(self.__batch_size):\n",
    "            img = cv2.imread(os.path.join(self.__images_folder_path, fnames[i]))[:,:,::-1]\n",
    "            min_size = min(img.shape[:2])\n",
    "            img = img[(img.shape[0] - min_size)//2:(img.shape[0] + min_size)//2,\n",
    "                      (img.shape[1] - min_size)//2:(img.shape[1] + min_size)//2]\n",
    "            img = cv2.resize(img, (self.__images_size,)*2)\n",
    "            result[i,] = img.astype(np.float32)/255\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveGAN(object):\n",
    "    def __init__(self, latent_dim=128, initial_image_size=4, final_image_size=512):\n",
    "        self.__latent_dim = latent_dim\n",
    "        self.__initial_image_size = initial_image_size\n",
    "        self.__final_image_size= final_image_size\n",
    "\n",
    "        self.__current_image_size = self.__initial_image_size\n",
    "\n",
    "        self.__generator_input = None\n",
    "        self.__generator_output_pre_rgb = None\n",
    "        self.__discriminator_input_post_rgb = None\n",
    "        self.__discriminator_output = None\n",
    "\n",
    "        self.__input_combine_layer = None\n",
    "        self.__output_combine_layer = None\n",
    "\n",
    "        self.__to_rgb_output = None\n",
    "        self.__from_rgb_input = None\n",
    "\n",
    "        self.__generator = self.__init_generator()\n",
    "        self.__discriminator = self.__init_discriminator()\n",
    "        self.__gan = self.__init_gan()\n",
    "    \n",
    "    @property\n",
    "    def generator(self):\n",
    "        return self.__generator\n",
    "\n",
    "    @property\n",
    "    def discriminator(self):\n",
    "        return self.__discriminator\n",
    "\n",
    "    @property\n",
    "    def gan(self):\n",
    "        return self.__gan\n",
    "\n",
    "    def fit(self, image_generator, lr=.01):\n",
    "        pass\n",
    "\n",
    "    def __init_generator(self):\n",
    "        self.__generator_input = x = Input((1, 1, self.__latent_dim))\n",
    "\n",
    "        x = Conv2DTranspose(self.__latent_dim, 4, activation='relu')(x)\n",
    "        x = Conv2D(self.__latent_dim, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "        output_size = 4\n",
    "\n",
    "        while output_size < self.__initial_image_size:\n",
    "            filters = self.__filters_count(output_size)\n",
    "\n",
    "            x = UpSampling2D()(x)\n",
    "            x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "            if (output_size << 1) < self.__initial_image_size:\n",
    "                x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "            else:\n",
    "                self.__generator_output_pre_rgb = x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "            output_size <<= 1\n",
    "\n",
    "        self.__to_rgb_output = x = Conv2D(3, 1, padding='same', activation='relu')(x)\n",
    "\n",
    "        return keras.Model(self.__generator_input, self.__to_rgb_output, name='generator')\n",
    "\n",
    "    def __init_discriminator(self):\n",
    "        discriminator_input = x = Input((self.__initial_image_size, self.__initial_image_size, 3))\n",
    "\n",
    "        self.__from_rgb_input = x = Conv2D(self.__filters_count(self.__initial_image_size), 1, padding='same', activation='relu')(x)\n",
    "\n",
    "        output_size = self.__initial_image_size\n",
    "        \n",
    "        filters = self.__filters_count(output_size)\n",
    "        \n",
    "        self.__discriminator_input_post_rgb = x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "        x = MaxPool2D()(x)\n",
    "\n",
    "        output_size >>= 1\n",
    "\n",
    "        while output_size > 4:\n",
    "            filters = self.__filters_count(output_size)\n",
    "            \n",
    "            x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "            x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "            x = MaxPool2D()(x)\n",
    "\n",
    "            output_size >>= 1\n",
    "        x = Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "        x = Conv2D(self.__latent_dim, 4, activation='relu')(x)\n",
    "        self.__discriminator_output = x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        return keras.Model(discriminator_input, self.__discriminator_output, name='discriminator')\n",
    "    \n",
    "    def __init_gan(self):\n",
    "        gan_input = x = Input((1, 1, self.__latent_dim))\n",
    "\n",
    "        return keras.Model(gan_input, self.__discriminator(self.__generator(gan_input)), name='gan')\n",
    "    \n",
    "    def increase_image_size_transition_step(self):\n",
    "        self.__current_image_size <<= 1\n",
    "        \n",
    "    def increase_image_size_final_step(self):\n",
    "        filters = self.__filters_count(self.__current_image_size)\n",
    "\n",
    "        # generator\n",
    "        x = UpSampling2D()(self.__generator_output_pre_rgb)\n",
    "        x = Conv2D(filters, 3, padding='same')(x)\n",
    "        self.__generator_output_pre_rgb = x = Conv2D(filters, 3, padding='same')(x)\n",
    "\n",
    "        self.__to_rgb_output = x = Conv2D(3, 1, padding='same')(x)\n",
    "\n",
    "        self.__generator = keras.Model(self.__generator_input, self.__to_rgb_output)\n",
    "\n",
    "        # discriminator\n",
    "        discriminator_input = x = Input((self.__current_image_size, self.__current_image_size, 3))\n",
    "\n",
    "        self.__from_rgb_input = x = Conv2D(self.__filters_count(self.__current_image_size), 1, padding='same')(x)\n",
    "\n",
    "        self.__discriminator_input_post_rgb = x = Conv2D(filters, 3, padding='same')(x)\n",
    "        x = Conv2D(filters, 3, padding='same')(x)\n",
    "        x = MaxPool2D()(x)\n",
    "        \n",
    "        for layer in self.__discriminator.layers[2:]:\n",
    "            x = layer(x)\n",
    "\n",
    "        self.__discriminator = keras.Model(discriminator_input, x)\n",
    "\n",
    "        self.__discriminator.summary(line_length=100, expand_nested=True)\n",
    "\n",
    "        self.__gan = self.__init_gan()\n",
    "\n",
    "    def __filters_count(self, output_size):\n",
    "        filters = self.__latent_dim\n",
    "        while output_size*filters >= self.__final_image_size*16:\n",
    "            filters /= 2\n",
    "        \n",
    "        return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progan = ProgressiveGAN(initial_image_size=8)\n",
    "progan.gan.summary(line_length=100, expand_nested=True)\n",
    "progan.increase_image_size_transition_step()\n",
    "progan.increase_image_size_final_step()\n",
    "progan.gan.summary(line_length=100, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageGenerator(r'E:\\Workspace\\datasets\\cats', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen.set_images_size(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = img_gen.get_batch()\n",
    "plt.figure(figsize=(64, 8))\n",
    "\n",
    "plt.imshow(np.vstack([np.hstack([batch[8*j + i] for i in range(8)]) for j in range(4)]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(r'E:\\Workspace\\datasets\\cats', '00000001_005.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.resize((64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
